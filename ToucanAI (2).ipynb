{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKS-VRrqD-rW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "09XLuyD6p0Qx",
    "outputId": "7ab76f6e-236c-4141-e50d-54070fb9998a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>QorA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did his mother die of pneumonia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it derived from the Latin spoken by the rom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why did Bequerel win the Nobel Prize in Physics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where is Jakarta located</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9  screens, but felt that was too much of a sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  QorA\n",
       "0                   Did his mother die of pneumonia      1\n",
       "1  Is it derived from the Latin spoken by the rom...     1\n",
       "2   Why did Bequerel win the Nobel Prize in Physics      1\n",
       "3                           Where is Jakarta located     1\n",
       "4  9  screens, but felt that was too much of a sa...     0"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST DATA\n",
    "traindf = pd.read_csv('testData.csv', delimiter = ',')\n",
    "traindf = traindf.dropna(axis =1)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "j1gE8xGrEUf6",
    "outputId": "2ee5dcd9-b1e6-418c-a7aa-93c6648aa92c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
      "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.15.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
      "Requirement already satisfied: en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
      "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ls3pDxkKD-rc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TRAINING DATA\n",
    "in_txt = open(\"Toucan/test-inputs.txt\").read().splitlines()\n",
    "document = []\n",
    "doc = {}\n",
    "l = []\n",
    "for line in in_txt:\n",
    "    l.append(line)\n",
    "    document.append(nlp(line)) \n",
    "doc = {'sent': l}\n",
    "docdf = pd.DataFrame.from_dict(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "uHPGABgMD-ro",
    "outputId": "e5c02652-5caa-4ea2-b866-0b0066f13910"
   },
   "outputs": [],
   "source": [
    "#TRAINING DATA TO NLP\n",
    "s_list = []\n",
    "for index, row, q in traindf.itertuples():\n",
    "    traindf['Sentence'][index] = nlp(traindf['Sentence'][index])\n",
    "    s_list.append(traindf['Sentence'][index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SEqHMjDb08b5",
    "outputId": "c417753e-a135-46d1-aa06-122b9d00852a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'    if token.dep_ == \"ROOT\":\\n        root_token = token.tag_\\n        ttraindf[\\'RootToken\\'][token.i] = root_token  '"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GET TOKEN TAGS FROM TRAINING DATA\n",
    "def get_token_tag(df):\n",
    "    question_df = pd.DataFrame(columns = ['WHpos', 'WHword', 'WHnbor']) #, 'RootToken'])\n",
    "    for t in df:\n",
    "        wh_pos = \" \"\n",
    "        wh_word = \" \"\n",
    "        wh_bi_gram = []\n",
    "        wh_nbor_pos = \" \"\n",
    "        for token in t:\n",
    "            if token.tag_ == \"WDT\" or token.tag_ == \"WP\" or token.tag_ == \"WP$\" or token.tag_ == \"WRB\":\n",
    "                wh_pos = token.tag_\n",
    "                wh_word = token.text\n",
    "                if len(t)-1 != token.i:\n",
    "                    wh_nbor_pos = token.nbor() \n",
    "                wh_bi_gram.append(token.text)\n",
    "                wh_bi_gram.append(str(token.i + 1))\n",
    "    q_dict = {'WHpos': wh_pos, 'WHword': wh_word, 'WHnbor': wh_nbor_pos} #, 'Root-POS': root_token}\n",
    "    question_df = question_df.append(q_dict, ignore_index=True)\n",
    "    q_df = pd.get_dummies(question_df, columns = ['WHpos', 'WHword', 'WHnbor']) #, 'RootToken'])\n",
    "    return q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyuC_i8h_Ixy"
   },
   "outputs": [],
   "source": [
    "question_train_df = get_token_tag(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgbiHerUvVeD"
   },
   "outputs": [],
   "source": [
    "predict_test_df = get_token_tag(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwG5ADOirOwm"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Y63JbIMR8FaT",
    "outputId": "16c992c5-b708-4ee9-9122-8632d4a6216a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\nXT_train = pd.DataFrame(training_dict)\\nXT_train = csr_matrix(XT_train)\\n\\n\\nXT_predict = pd.DataFrame(predicting_dict)\\nXT_predict = csr_matrix(XT_predict)  \""
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING DATA MATRIX\n",
    "train = traindf['Sentence'].tolist()\n",
    "predict = docdf['sent'].tolist() \n",
    "both_list = list(set(train + predict))\n",
    "vl = []\n",
    "training_dict = {}\n",
    "for val in both_list:\n",
    "    if val not in traindf:\n",
    "        training_dict[val] = [0 for i in range(len(traindf.index))]\n",
    "    else:\n",
    "        training_dict[val] = list(traindf[val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aITXcLEf6ifu"
   },
   "outputs": [],
   "source": [
    "predicting_dict = {}\n",
    "for col in both_list:\n",
    "    if col not in docdf:\n",
    "        predicting_dict[col] = [0]\n",
    "    else:\n",
    "        predicting_dict[col] = list(docdf[col])  # KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCQ9Y3VrBp7F"
   },
   "outputs": [],
   "source": [
    "XT_predict = pd.DataFrame(predicting_dict)\n",
    "XT_train = pd.DataFrame(training_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xTWw_qMIxbJ"
   },
   "outputs": [],
   "source": [
    "#SVC\n",
    "def classifysvm(df_train, classdf, df_predict):\n",
    "    lin_clf = LinearSVC()\n",
    "    lin_clf.fit(df_train, classdf)\n",
    "    prediction = lin_clf.predict(df_predict)\n",
    "    return prediction, lin_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classdata = traindf['QorA']\n",
    "finalprediction, svclf = classifysvm(train, classdata, predict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ToucanAI.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
